{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whatsapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:55:16.052451Z",
     "start_time": "2020-12-06T00:55:15.565155Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns',200)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "file = '/home/ef/Documents/Diplomado/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:55:16.061255Z",
     "start_time": "2020-12-06T00:55:16.054506Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:55:19.572550Z",
     "start_time": "2020-12-06T00:55:16.064982Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ef/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "file += 'WhatsApp Chat with Naps 火拣.txt'\n",
    "import whatsapp as wa\n",
    "df = wa.read_chat(file)\n",
    "\n",
    "## Transformaci贸n y obtenci贸n de tipos de variables\n",
    "df,cat,num,autores = wa.TAD().transform(df)\n",
    "\n",
    "## Se tratan outliers\n",
    "for col in num:\n",
    "    df = wa.outlier(df,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:55:19.591712Z",
     "start_time": "2020-12-06T00:55:19.574667Z"
    }
   },
   "outputs": [],
   "source": [
    "## Se estructura y=f(X)\n",
    "df['OBJETIVO'] = df['Autor'].replace(autores)\n",
    "X = df[['Mensaje_limpio'] + cat + num]\n",
    "y = df['OBJETIVO']\n",
    "\n",
    "## Se separa train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size = 0.77, \n",
    "                                                    random_state = 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:55:19.609819Z",
     "start_time": "2020-12-06T00:55:19.594768Z"
    }
   },
   "outputs": [],
   "source": [
    "## Dummies para categ贸ricas\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse = False, handle_unknown = 'ignore')\n",
    "\n",
    "## Escala para num茅ricas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm_x = MinMaxScaler()\n",
    "\n",
    "## Frecuencia de palabras para texto\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(ngram_range = (1, 1), \n",
    "                     min_df = 10, \n",
    "                     max_features = 100)\n",
    "\n",
    "## Se aplicar谩 transformaci贸n para cada tipo de columnas\n",
    "from sklearn.compose import ColumnTransformer\n",
    "prep = ColumnTransformer(transformers=[('OHE', ohe, cat),\n",
    "                                       ('Scale', mm_x, num), \n",
    "                                       ('CountV', cv, 'Mensaje_limpio')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:55:20.080994Z",
     "start_time": "2020-12-06T00:55:19.617078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EF</th>\n",
       "      <th>Iv谩n Jard贸n</th>\n",
       "      <th>Kevin Bacon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jaja</td>\n",
       "      <td>jaja</td>\n",
       "      <td>jaja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abuebo</td>\n",
       "      <td>we</td>\n",
       "      <td>jardon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pa</td>\n",
       "      <td>wey</td>\n",
       "      <td>mas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ah</td>\n",
       "      <td>voy</td>\n",
       "      <td>ah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mas</td>\n",
       "      <td>verga</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amigo</td>\n",
       "      <td>bien</td>\n",
       "      <td>bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>we</td>\n",
       "      <td>asi</td>\n",
       "      <td>amigo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>brob</td>\n",
       "      <td>mas</td>\n",
       "      <td>bro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bien</td>\n",
       "      <td>amigos</td>\n",
       "      <td>solo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jalo</td>\n",
       "      <td>kevin</td>\n",
       "      <td>efras</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EF Iv谩n Jard贸n Kevin Bacon\n",
       "0     jaja        jaja        jaja\n",
       "1       si          si          si\n",
       "2   abuebo          we      jardon\n",
       "3       pa         wey         mas\n",
       "4       ah         voy          ah\n",
       "5      mas       verga          we\n",
       "6    amigo        bien        bien\n",
       "7       we         asi       amigo\n",
       "8     brob         mas         bro\n",
       "9     bien      amigos        solo\n",
       "10    jalo       kevin       efras"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Top palabras por autor\n",
    "wa.words(df,cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T23:24:35.954707Z",
     "start_time": "2020-12-05T23:24:35.944547Z"
    }
   },
   "outputs": [],
   "source": [
    "scoring = 'roc_auc' if len(autores) == 2 else 'accuracy'\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "param_logreg = {'penalty':['l1', 'l2', 'elasticnet'], \n",
    "                'C':[x+y/10 for x in range(11) for y in range(1,11)], \n",
    "                'class_weight':['None','balanced'],\n",
    "                'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "                }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "search_logreg = GridSearchCV(param_grid = param_logreg, \n",
    "                             cv = 4, \n",
    "                             n_jobs = -1, \n",
    "                             scoring = scoring,\n",
    "                             estimator = logreg,\n",
    "                             verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T23:24:37.882785Z",
     "start_time": "2020-12-05T23:24:37.604835Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "param_forest = {'n_estimators': [x for x in range(1400, 1500, 10)],\n",
    "                'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'class_weight': ['balanced', None],\n",
    "                'min_samples_split': [x for x in range(10, 22)],\n",
    "                'min_samples_leaf': [x/1000 for x in range(1, 6)]\n",
    "               }\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "search_forest = RandomizedSearchCV(param_distributions = param_forest, \n",
    "                                   cv = 4, \n",
    "                                   n_jobs = -1, \n",
    "                                   scoring = scoring,\n",
    "                                   estimator = forest,\n",
    "                                   verbose = 5,\n",
    "                                   n_iter = 30,\n",
    "                                   random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T23:24:39.655718Z",
     "start_time": "2020-12-05T23:24:39.648631Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "param_ada={'n_estimators':[x for x in range(50,550,50)],\n",
    "           'learning_rate':[x/100 for x in range(1,111)]\n",
    "          }\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "search_ada = RandomizedSearchCV(param_distributions = param_ada, \n",
    "                                cv = 4, \n",
    "                                n_jobs = -1, \n",
    "                                scoring = scoring, \n",
    "                                estimator = ada, \n",
    "                                verbose = 5,\n",
    "                                n_iter = 50,\n",
    "                                random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T23:24:53.096143Z",
     "start_time": "2020-12-05T23:24:52.012170Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "param_xgb = {'learning_rate':[x/100 for x in range(1,111)],\n",
    "             'n_estimators':[x for x in range(1,111)],\n",
    "             'max_depth':[x for x in range(1,11)], \n",
    "             'min_child_weight':[x for x in range(1,111)],\n",
    "             'objective':['count:poisson','multi:softmax'],\n",
    "             'subsample':[x/100 for x in range(50,111)], \n",
    "             'colsample_bytree':[x/100 for x in range(50,111)], \n",
    "            }\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "search_xgb = RandomizedSearchCV(param_distributions = param_xgb, \n",
    "                                cv = 4, \n",
    "                                n_jobs = -1, \n",
    "                                scoring = scoring, \n",
    "                                estimator = xgb, \n",
    "                                verbose = 5,\n",
    "                                n_iter = 600,\n",
    "                                random_state = 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T23:26:03.068930Z",
     "start_time": "2020-12-05T23:26:03.061980Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vc = VotingClassifier(estimators = [('LogReg', search_logreg), \n",
    "                                    ('Forest', search_forest), \n",
    "                                    ('ADA', search_ada), \n",
    "                                    ('XGB',search_xgb)], \n",
    "                      voting = 'soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T23:44:28.842819Z",
     "start_time": "2020-12-05T23:26:11.970147Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "modelo = Pipeline(steps=[('preproc', prep),\n",
    "                         ('modelo', vc)])\n",
    "\n",
    "modelo.fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:32:24.957546Z",
     "start_time": "2020-12-06T00:32:24.778453Z"
    }
   },
   "outputs": [],
   "source": [
    "## Variables que m谩s se usan para diferenciar al autor/a\n",
    "wa.top_variables(vc,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:37:44.654571Z",
     "start_time": "2020-12-06T00:37:44.020548Z"
    }
   },
   "outputs": [],
   "source": [
    "## Certeza en el conjunto de train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = pd.DataFrame(confusion_matrix(y_true = y_train,\n",
    "                                   y_pred = modelo.predict(X_train))/len(y_train), \n",
    "                  index = [{y: x for x, y in autores.items()\n",
    "                           }[n] for n in list(sorted(np.unique(y_train)))], \n",
    "                  columns = [{y: x for x, y in autores.items()\n",
    "                             }[n] for n in list(sorted(np.unique(y_train)))])\n",
    "display(cm)\n",
    "\n",
    "## Tiene buena acertividad (suma de diagonal en la matriz de confusi贸n)\n",
    "'Accuracy de {:.2%}'.format(np.asarray(cm).trace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:38:05.855613Z",
     "start_time": "2020-12-06T00:38:05.518103Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Y en test\n",
    "cm = pd.DataFrame(confusion_matrix(y_true = y_test,\n",
    "                                   y_pred = modelo.predict(X_test))/len(y_test), \n",
    "                  index = [{y: x for x, y in autores.items()\n",
    "                           }[n] for n in list(sorted(np.unique(y_test)))], \n",
    "                  columns = [{y: x for x, y in autores.items()\n",
    "                             }[n] for n in list(sorted(np.unique(y_test)))])\n",
    "display(cm)\n",
    "\n",
    "## Tiene buena acertividad (suma de diagonal en la matriz de confusi贸n)\n",
    "'Accuracy de {:.2%}'.format(np.asarray(cm).trace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:38:24.748797Z",
     "start_time": "2020-12-06T00:38:24.628291Z"
    }
   },
   "outputs": [],
   "source": [
    "## Guardar OHE, MinMax y modelo\n",
    "import pickle\n",
    "with open('modelo_whatsapp_naps.pkl', \"wb\") as f:\n",
    "    pickle.dump(modelo, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:38:33.975157Z",
     "start_time": "2020-12-06T00:38:33.796585Z"
    }
   },
   "outputs": [],
   "source": [
    "## Abrir el pickle con lo necesario para validar\n",
    "import pickle    \n",
    "with open('modelo_whatsapp_naps.pkl', \"rb\") as f:\n",
    "    modelo = pickle.load(f)\n",
    "\n",
    "## Listo para usarse\n",
    "display('Transformadores:')\n",
    "display([x[1] for x in modelo.get_params()['steps'][0][1].get_params()['transformers']])\n",
    "display('Modelos:')\n",
    "[x.best_estimator_ for x in modelo.get_params()['modelo'].estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:42:07.680281Z",
     "start_time": "2020-12-06T00:42:07.664073Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Fecha'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:43:47.738092Z",
     "start_time": "2020-12-06T00:43:46.803187Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns',200)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "file = '/home/ef/Documents/Diplomado/data/WhatsApp Chat with Naps_val.txt'\n",
    "\n",
    "## Podemos crear un m贸dulo con funciones y clases que ejecuten todo el proceso anterior\n",
    "import whatsapp as wa\n",
    "df = wa.read_chat(file)\n",
    "\n",
    "## Transformaci贸n y obtenci贸n de tipos de variables\n",
    "df,cat,num,autores = wa.TAD().transform(df)\n",
    "\n",
    "## Se estructura y=f(X)\n",
    "df['OBJETIVO'] = df['Autor'].replace(autores)\n",
    "X = df[['Mensaje_limpio'] + cat + num]\n",
    "y = df['OBJETIVO']\n",
    "\n",
    "## Se predice sobre datos nuevos\n",
    "val = df.join(pd.DataFrame(modelo.predict(X),\n",
    "                           columns = ['Estimado']\n",
    "                          ).replace({y: x for x, y in autores.items()}))\n",
    "\n",
    "## Qu茅 acertividad hay en la validaci贸n?\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = pd.DataFrame(confusion_matrix(y_true = val['Autor'],\n",
    "                                   y_pred = val['Estimado'])/len(val), \n",
    "                  index = [x for x in autores], \n",
    "                  columns = [x for x in autores])\n",
    "display(cm)\n",
    "\n",
    "## Con buena acertividad (suma de diagonal en la matriz de confusi贸n)\n",
    "'Accuracy de {:.2%}'.format(np.asarray(cm).trace())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T02:08:06.009669Z",
     "start_time": "2020-12-05T02:08:05.992885Z"
    }
   },
   "outputs": [],
   "source": [
    "## Tono para cuando termina c贸digo\n",
    "from IPython.lib.display import Audio\n",
    "import numpy as np\n",
    "\n",
    "framerate = 4410\n",
    "play_time_seconds = 1\n",
    "\n",
    "t = np.linspace(0, play_time_seconds, framerate*play_time_seconds)\n",
    "audio_data = np.sin(5*np.pi*300*t) + np.sin(2*np.pi*240*t)\n",
    "\n",
    "## La siguiente l铆nea debe ir debajo del c贸digo p que suene\n",
    "Audio(audio_data, rate=framerate, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T02:08:06.110467Z",
     "start_time": "2020-12-05T02:08:06.012835Z"
    }
   },
   "outputs": [],
   "source": [
    "## Tiempo total para correr la modelaci贸n\n",
    "end = time.time()\n",
    "tiempo_tot = end - start\n",
    "import math\n",
    "str(int(math.floor(tiempo_tot/60\n",
    "                  )\n",
    "       )\n",
    "   ) + \" minutos con \" + '{:.2f}'.format(60*(tiempo_tot/60 - math.floor(tiempo_tot/60\n",
    "                                                                       )\n",
    "                                            )\n",
    "                                        ) + \" segundos\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "461.973px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
