{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whatsapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:55:16.052451Z",
     "start_time": "2020-12-06T00:55:15.565155Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns',200)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "file = '/home/ef/Documents/Diplomado/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:55:16.061255Z",
     "start_time": "2020-12-06T00:55:16.054506Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:55:19.572550Z",
     "start_time": "2020-12-06T00:55:16.064982Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ef/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "file += 'WhatsApp Chat with Naps 🐻🐼🐯.txt'\n",
    "import whatsapp as wa\n",
    "df = wa.read_chat(file)\n",
    "\n",
    "## Transformación y obtención de tipos de variables\n",
    "df,cat,num,autores = wa.TAD().transform(df)\n",
    "\n",
    "## Se tratan outliers\n",
    "for col in num:\n",
    "    df = wa.outlier(df,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:55:19.591712Z",
     "start_time": "2020-12-06T00:55:19.574667Z"
    }
   },
   "outputs": [],
   "source": [
    "## Se estructura y=f(X)\n",
    "df['OBJETIVO'] = df['Autor'].replace(autores)\n",
    "X = df[['Mensaje_limpio'] + cat + num]\n",
    "y = df['OBJETIVO']\n",
    "\n",
    "## Se separa train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size = 0.77, \n",
    "                                                    random_state = 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:55:19.609819Z",
     "start_time": "2020-12-06T00:55:19.594768Z"
    }
   },
   "outputs": [],
   "source": [
    "## Dummies para categóricas\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse = False, handle_unknown = 'ignore')\n",
    "\n",
    "## Escala para numéricas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm_x = MinMaxScaler()\n",
    "\n",
    "## Frecuencia de palabras para texto\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(ngram_range = (1, 1), \n",
    "                     min_df = 10, \n",
    "                     max_features = 100)\n",
    "\n",
    "## Se aplicará transformación para cada tipo de columnas\n",
    "from sklearn.compose import ColumnTransformer\n",
    "prep = ColumnTransformer(transformers=[('OHE', ohe, cat),\n",
    "                                       ('Scale', mm_x, num), \n",
    "                                       ('CountV', cv, 'Mensaje_limpio')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:55:20.080994Z",
     "start_time": "2020-12-06T00:55:19.617078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EF</th>\n",
       "      <th>Iván Jardón</th>\n",
       "      <th>Kevin Bacon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jaja</td>\n",
       "      <td>jaja</td>\n",
       "      <td>jaja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abuebo</td>\n",
       "      <td>we</td>\n",
       "      <td>jardon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pa</td>\n",
       "      <td>wey</td>\n",
       "      <td>mas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ah</td>\n",
       "      <td>voy</td>\n",
       "      <td>ah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mas</td>\n",
       "      <td>verga</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amigo</td>\n",
       "      <td>bien</td>\n",
       "      <td>bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>we</td>\n",
       "      <td>asi</td>\n",
       "      <td>amigo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>brob</td>\n",
       "      <td>mas</td>\n",
       "      <td>bro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bien</td>\n",
       "      <td>amigos</td>\n",
       "      <td>solo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jalo</td>\n",
       "      <td>kevin</td>\n",
       "      <td>efras</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EF Iván Jardón Kevin Bacon\n",
       "0     jaja        jaja        jaja\n",
       "1       si          si          si\n",
       "2   abuebo          we      jardon\n",
       "3       pa         wey         mas\n",
       "4       ah         voy          ah\n",
       "5      mas       verga          we\n",
       "6    amigo        bien        bien\n",
       "7       we         asi       amigo\n",
       "8     brob         mas         bro\n",
       "9     bien      amigos        solo\n",
       "10    jalo       kevin       efras"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Top palabras por autor\n",
    "wa.words(df,cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T23:24:35.954707Z",
     "start_time": "2020-12-05T23:24:35.944547Z"
    }
   },
   "outputs": [],
   "source": [
    "scoring = 'roc_auc' if len(autores) == 2 else 'accuracy'\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "param_logreg = {'penalty':['l1', 'l2', 'elasticnet'], \n",
    "                'C':[x+y/10 for x in range(11) for y in range(1,11)], \n",
    "                'class_weight':['None','balanced'],\n",
    "                'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "                }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "search_logreg = GridSearchCV(param_grid = param_logreg, \n",
    "                             cv = 4, \n",
    "                             n_jobs = -1, \n",
    "                             scoring = scoring,\n",
    "                             estimator = logreg,\n",
    "                             verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T23:24:37.882785Z",
     "start_time": "2020-12-05T23:24:37.604835Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "param_forest = {'n_estimators': [x for x in range(1400, 1500, 10)],\n",
    "                'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'class_weight': ['balanced', None],\n",
    "                'min_samples_split': [x for x in range(10, 22)],\n",
    "                'min_samples_leaf': [x/1000 for x in range(1, 6)]\n",
    "               }\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "search_forest = RandomizedSearchCV(param_distributions = param_forest, \n",
    "                                   cv = 4, \n",
    "                                   n_jobs = -1, \n",
    "                                   scoring = scoring,\n",
    "                                   estimator = forest,\n",
    "                                   verbose = 5,\n",
    "                                   n_iter = 30,\n",
    "                                   random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T23:24:39.655718Z",
     "start_time": "2020-12-05T23:24:39.648631Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "param_ada={'n_estimators':[x for x in range(50,550,50)],\n",
    "           'learning_rate':[x/100 for x in range(1,111)]\n",
    "          }\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "search_ada = RandomizedSearchCV(param_distributions = param_ada, \n",
    "                                cv = 4, \n",
    "                                n_jobs = -1, \n",
    "                                scoring = scoring, \n",
    "                                estimator = ada, \n",
    "                                verbose = 5,\n",
    "                                n_iter = 50,\n",
    "                                random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T23:24:53.096143Z",
     "start_time": "2020-12-05T23:24:52.012170Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "param_xgb = {'learning_rate':[x/100 for x in range(1,111)],\n",
    "             'n_estimators':[x for x in range(1,111)],\n",
    "             'max_depth':[x for x in range(1,11)], \n",
    "             'min_child_weight':[x for x in range(1,111)],\n",
    "             'objective':['count:poisson','multi:softmax'],\n",
    "             'subsample':[x/100 for x in range(50,111)], \n",
    "             'colsample_bytree':[x/100 for x in range(50,111)], \n",
    "            }\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "search_xgb = RandomizedSearchCV(param_distributions = param_xgb, \n",
    "                                cv = 4, \n",
    "                                n_jobs = -1, \n",
    "                                scoring = scoring, \n",
    "                                estimator = xgb, \n",
    "                                verbose = 5,\n",
    "                                n_iter = 600,\n",
    "                                random_state = 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T23:26:03.068930Z",
     "start_time": "2020-12-05T23:26:03.061980Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vc = VotingClassifier(estimators = [('LogReg', search_logreg), \n",
    "                                    ('Forest', search_forest), \n",
    "                                    ('ADA', search_ada), \n",
    "                                    ('XGB',search_xgb)], \n",
    "                      voting = 'soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T23:44:28.842819Z",
     "start_time": "2020-12-05T23:26:11.970147Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "modelo = Pipeline(steps=[('preproc', prep),\n",
    "                         ('modelo', vc)])\n",
    "\n",
    "modelo.fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:32:24.957546Z",
     "start_time": "2020-12-06T00:32:24.778453Z"
    }
   },
   "outputs": [],
   "source": [
    "## Variables que más se usan para diferenciar al autor/a\n",
    "wa.top_variables(vc,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:37:44.654571Z",
     "start_time": "2020-12-06T00:37:44.020548Z"
    }
   },
   "outputs": [],
   "source": [
    "## Certeza en el conjunto de train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = pd.DataFrame(confusion_matrix(y_true = y_train,\n",
    "                                   y_pred = modelo.predict(X_train))/len(y_train), \n",
    "                  index = [{y: x for x, y in autores.items()\n",
    "                           }[n] for n in list(sorted(np.unique(y_train)))], \n",
    "                  columns = [{y: x for x, y in autores.items()\n",
    "                             }[n] for n in list(sorted(np.unique(y_train)))])\n",
    "display(cm)\n",
    "\n",
    "## Tiene buena acertividad (suma de diagonal en la matriz de confusión)\n",
    "'Accuracy de {:.2%}'.format(np.asarray(cm).trace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:38:05.855613Z",
     "start_time": "2020-12-06T00:38:05.518103Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Y en test\n",
    "cm = pd.DataFrame(confusion_matrix(y_true = y_test,\n",
    "                                   y_pred = modelo.predict(X_test))/len(y_test), \n",
    "                  index = [{y: x for x, y in autores.items()\n",
    "                           }[n] for n in list(sorted(np.unique(y_test)))], \n",
    "                  columns = [{y: x for x, y in autores.items()\n",
    "                             }[n] for n in list(sorted(np.unique(y_test)))])\n",
    "display(cm)\n",
    "\n",
    "## Tiene buena acertividad (suma de diagonal en la matriz de confusión)\n",
    "'Accuracy de {:.2%}'.format(np.asarray(cm).trace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:38:24.748797Z",
     "start_time": "2020-12-06T00:38:24.628291Z"
    }
   },
   "outputs": [],
   "source": [
    "## Guardar OHE, MinMax y modelo\n",
    "import pickle\n",
    "with open('modelo_whatsapp_naps.pkl', \"wb\") as f:\n",
    "    pickle.dump(modelo, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:38:33.975157Z",
     "start_time": "2020-12-06T00:38:33.796585Z"
    }
   },
   "outputs": [],
   "source": [
    "## Abrir el pickle con lo necesario para validar\n",
    "import pickle    \n",
    "with open('modelo_whatsapp_naps.pkl', \"rb\") as f:\n",
    "    modelo = pickle.load(f)\n",
    "\n",
    "## Listo para usarse\n",
    "display('Transformadores:')\n",
    "display([x[1] for x in modelo.get_params()['steps'][0][1].get_params()['transformers']])\n",
    "display('Modelos:')\n",
    "[x.best_estimator_ for x in modelo.get_params()['modelo'].estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:42:07.680281Z",
     "start_time": "2020-12-06T00:42:07.664073Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Fecha'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T00:43:47.738092Z",
     "start_time": "2020-12-06T00:43:46.803187Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns',200)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "file = '/home/ef/Documents/Diplomado/data/WhatsApp Chat with Naps_val.txt'\n",
    "\n",
    "## Podemos crear un módulo con funciones y clases que ejecuten todo el proceso anterior\n",
    "import whatsapp as wa\n",
    "df = wa.read_chat(file)\n",
    "\n",
    "## Transformación y obtención de tipos de variables\n",
    "df,cat,num,autores = wa.TAD().transform(df)\n",
    "\n",
    "## Se estructura y=f(X)\n",
    "df['OBJETIVO'] = df['Autor'].replace(autores)\n",
    "X = df[['Mensaje_limpio'] + cat + num]\n",
    "y = df['OBJETIVO']\n",
    "\n",
    "## Se predice sobre datos nuevos\n",
    "val = df.join(pd.DataFrame(modelo.predict(X),\n",
    "                           columns = ['Estimado']\n",
    "                          ).replace({y: x for x, y in autores.items()}))\n",
    "\n",
    "## Qué acertividad hay en la validación?\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = pd.DataFrame(confusion_matrix(y_true = val['Autor'],\n",
    "                                   y_pred = val['Estimado'])/len(val), \n",
    "                  index = [x for x in autores], \n",
    "                  columns = [x for x in autores])\n",
    "display(cm)\n",
    "\n",
    "## Con buena acertividad (suma de diagonal en la matriz de confusión)\n",
    "'Accuracy de {:.2%}'.format(np.asarray(cm).trace())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T02:08:06.009669Z",
     "start_time": "2020-12-05T02:08:05.992885Z"
    }
   },
   "outputs": [],
   "source": [
    "## Tono para cuando termina código\n",
    "from IPython.lib.display import Audio\n",
    "import numpy as np\n",
    "\n",
    "framerate = 4410\n",
    "play_time_seconds = 1\n",
    "\n",
    "t = np.linspace(0, play_time_seconds, framerate*play_time_seconds)\n",
    "audio_data = np.sin(5*np.pi*300*t) + np.sin(2*np.pi*240*t)\n",
    "\n",
    "## La siguiente línea debe ir debajo del código p que suene\n",
    "Audio(audio_data, rate=framerate, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T02:08:06.110467Z",
     "start_time": "2020-12-05T02:08:06.012835Z"
    }
   },
   "outputs": [],
   "source": [
    "## Tiempo total para correr la modelación\n",
    "end = time.time()\n",
    "tiempo_tot = end - start\n",
    "import math\n",
    "str(int(math.floor(tiempo_tot/60\n",
    "                  )\n",
    "       )\n",
    "   ) + \" minutos con \" + '{:.2f}'.format(60*(tiempo_tot/60 - math.floor(tiempo_tot/60\n",
    "                                                                       )\n",
    "                                            )\n",
    "                                        ) + \" segundos\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "461.973px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
